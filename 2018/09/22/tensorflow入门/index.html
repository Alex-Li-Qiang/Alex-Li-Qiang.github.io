<!DOCTYPE HTML>
<html>

<head>
	<link rel="bookmark"  type="image/x-icon"  href="/img/logo_miccall.png"/>
	<link rel="shortcut icon" href="/img/logo_miccall.png">

	<a href="https://github.com/Alex-Li-Qiang"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>

	
			    <title>
    李强的博客世界
    </title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="/css/mic_main.css" />
    <link rel="stylesheet" href="/css/dropdownMenu.css" />
    <meta name="keywords" content="miccall" />
    
    	<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	 
    <noscript>
        <link rel="stylesheet" href="/css/noscript.css" />
    </noscript>
    <style type="text/css">
        body:before {
          content: ' ';
          position: fixed;
          top: 0;
          background: url('/img/bg.jpg') center 0 no-repeat;
          right: 0;
          bottom: 0;
          left: 0;
          background-size: cover; 
        }
    </style>

			    
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script async type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


    <script src="/js/jquery.min.js"></script>
    <script src="/js/jquery.scrollex.min.js"></script>
    <script src="/js/jquery.scrolly.min.js"></script>
    <script src="/js/skel.min.js"></script>
    <script src="/js/util.js"></script>
    <script src="/js/main.js"></script>
	

	{% if theme.canvas_nest %}
	<script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script>
	{% endif %}


</head>
    
		
<!-- Layouts -->



<!--  代码渲染  -->
<link rel="stylesheet" href="/css/prism_coy.css" />
<link rel="stylesheet" href="/css/typo.css" />
<!-- 文章页 -->
<body class="is-loading">
    <!-- Wrapper 外包 s-->
    <div id="wrapper" class="fade-in">
        <!-- Intro 头部显示 s -->
        <!-- Intro 头部显示 e -->
        <!-- Header 头部logo start -->
        <header id="header">
    <a href="/" class="logo">li'qiang</a>
</header>
        <!-- Nav 导航条 start -->
        <nav id="nav" class="special" >
            <ul class="menu links" >
			<!-- Homepage  主页  --> 
			<li >
	            <a href="/" rel="nofollow">Home</a>
	        </li>
			<!-- categories_name  分类   --> 
	        
	        <li class="active">
	            <a href="#s1">categories</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="category-link" href="/categories/AI/">AI</a></li><li><a class="category-link" href="/categories/LINUX/">LINUX</a></li><li><a class="category-link" href="/categories/大数据/">大数据</a></li><li><a class="category-link" href="/categories/网站/">网站</a>
	                    </ul>
	        </li>
	        
	        <!-- archives  归档   --> 
	        
	        <li class="active">
	            <a href="#s1">archives</a>
	                    <ul class="submenu">
	                        <li>
	                        <a class="archive-link" href="/archives/2018/09/">September 2018</a>
	                    </ul>
	        </li>
	        
	        
		        <!-- Pages 自定义   -->
		        
		        <li>
		            <a href="/个人简历/" title="resume">
		                resume
		            </a>
		        </li>
		        
		        <li>
		            <a href="/group/" title="group">
		                group
		            </a>
		        </li>
		        
		        <li>
		            <a href="/gallery/" title="gallery">
		                gallery
		            </a>
		        </li>
		        
		        <li>
		            <a href="/tag/" title="tags">
		                tags
		            </a>
		        </li>
		        
		        <li>
		            <a href="/dream/" title="dreams">
		                dreams
		            </a>
		        </li>
		        


            </ul>
            <!-- icons 图标   -->
			<ul class="icons">
                    
                    <li>
                        <a title="github" href="https://github.com/Alex-Li-Qiang" target="_blank" rel="noopener">
                            <i class="icon fa fa-github"></i>
                        </a>
                    </li>
                    
                    <li>
                        <a title="500px" href="http://500px.com" target="_blank" rel="noopener">
                            <i class="icon fa fa-500px"></i>
                        </a>
                    </li>
                    
			</ul>
</nav>

        <div id="main" >
            <div class ="post_page_title_img" style="height: 25rem;background-image: url(https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1537606065886&amp;di=22550c82bbed8293d13a2376d621c546&amp;imgtype=0&amp;src=http%3A%2F%2Fpic.58pic.com%2F58pic%2F13%2F82%2F34%2F63Q58PICIZ9_1024.jpg);background-position: center; background-repeat:no-repeat; background-size:cover;-moz-background-size:cover;overflow:hidden;" >
                <a href="#" style="padding: 4rem 4rem 2rem 4rem ;"><h2 >TensorFlow入门</h2></a>
            </div>
            <!-- Post -->
            <div class="typo" style="padding: 3rem;">
                <hr>
<p>本文由深圳大学李强转载整理自CSDN 博客</p>
<h2 id="TensorFlow入门："><a href="#TensorFlow入门：" class="headerlink" title="TensorFlow入门："></a>TensorFlow入门：</h2><p>使用图 (graph) 来表示计算任务.<br>在被称之为 会话 (Session) 的上下文 (context) 中执行图.<br>使用 张量(tensor) 表示数据.<br>通过 变量 (Variable) 维护状态.<br>使用 feed 和 fetch 可以为任意的操作(arbitrary operation) 赋值或者从其中获取数据.</p>
<h2 id="一，基本语法："><a href="#一，基本语法：" class="headerlink" title="一，基本语法："></a>一，基本语法：</h2><p>语法例子1：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 创建2个矩阵，前者1行2列，后者2行1列，然后矩阵相乘：</span><br><span class="line">matrix1 = tf.constant([[3,3]])</span><br><span class="line">matrix2 = tf.constant([[2], [2]])</span><br><span class="line">product = tf.matmul(matrix1,matrix2)</span><br><span class="line"> </span><br><span class="line"># 上边的操作是定义图，然后用会话Session去计算：</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    result2 = sess.run(product)</span><br><span class="line">    print(result2)</span><br></pre></td></tr></table></figure></p>
<p>语法例子2：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"># 定义一个tensorflow的变量：</span><br><span class="line">state = tf.Variable(0, name=&apos;counter&apos;)</span><br><span class="line"># 定义常量</span><br><span class="line">one = tf.constant(1)</span><br><span class="line"># 定义加法步骤 (注: 此步并没有直接计算)</span><br><span class="line">new_value = tf.add(state, one)</span><br><span class="line"># 将 State 更新成 new_value</span><br><span class="line">update = tf.assign(state, new_value)</span><br><span class="line"># 变量Variable需要初始化并激活，并且打印的话只能通过sess.run()：</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"># 使用 Session 计算</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    for _ in range(3):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        print(sess.run(state))</span><br></pre></td></tr></table></figure></p>
<p>语法例子3：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 如果要传入值，用tensorflow的占位符，暂时存储变量，</span><br><span class="line"># 以这种形式feed数据：sess.run(***, feed_dict=&#123;input: **&#125;)</span><br><span class="line">#在 Tensorflow 中需要定义 placeholder 的 type ，一般为 float32 形式</span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line"># mul = multiply 是将input1和input2 做乘法运算，并输出为 output </span><br><span class="line">ouput = tf.multiply(input1, input2)</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    print(sess.run(ouput, feed_dict=&#123;input1: [7.], input2: [2.]&#125;))</span><br><span class="line"># 输出[ 14.]</span><br></pre></td></tr></table></figure></p>
<h2 id="二，小程序"><a href="#二，小程序" class="headerlink" title="二，小程序"></a>二，小程序</h2><hr>
<p>小程序例子1：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">import numpy as np</span><br><span class="line"> </span><br><span class="line"># 例子1，拟合y_data的函数，权重和偏置分别趋近0.1和0.3</span><br><span class="line"> </span><br><span class="line"># np.random.rand(100)生成100个[0,1]之间的随机数，构成1维数组</span><br><span class="line"># np.random.rand(2,3)生成2行3列的二维数组</span><br><span class="line">x_data = np.random.rand(100).astype(np.float32)</span><br><span class="line">y_data = x_data * 0.1 + 0.3</span><br><span class="line"> </span><br><span class="line"># 权重偏置这些不断更新的值用tf变量存储，</span><br><span class="line"># tf.random_uniform()的参数意义：(shape,min,max)</span><br><span class="line"># 偏置初始化为0</span><br><span class="line">weights = tf.Variable(tf.random_uniform([1],-1.0,1.0))</span><br><span class="line">biases = tf.Variable(tf.zeros([1]))</span><br><span class="line"> </span><br><span class="line">y = weights * x_data + biases</span><br><span class="line"> </span><br><span class="line"># 损失函数。tf.reduce_mean()是取均值。square是平方。</span><br><span class="line">loss = tf.reduce_mean(tf.square(y - y_data))</span><br><span class="line"> </span><br><span class="line"># 用梯度优化方法最小化损失函数。</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(0.5)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"> </span><br><span class="line"># tf变量是需要初始化的，而且后边计算时还需要sess.run(init)一下</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"> </span><br><span class="line"># Session进行计算</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    for step in range(201):</span><br><span class="line">        sess.run(train)</span><br><span class="line">        if step % 20 == 0:</span><br><span class="line">            print (step, sess.run(weights), sess.run(biases))</span><br></pre></td></tr></table></figure></p>
<p>小程序例子2：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"># 例子2，构建一个神经网络</span><br><span class="line"> </span><br><span class="line"># 添加神经层的函数，它有四个参数：输入值、输入的形状、输出的形状和激励函数，</span><br><span class="line"># Wx_plus_b是未激活的值，函数返回激活值。</span><br><span class="line">def add_layer(inputs, in_size, out_size,  activation_function=None):</span><br><span class="line">    # tf.random_normal()参数为shape，还可以指定均值和标准差</span><br><span class="line">    Weights = tf.Variable(tf.random_normal([in_size, out_size]))</span><br><span class="line">    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights) + biases</span><br><span class="line">    if activation_function is None:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    else:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">return outputs</span><br><span class="line"> </span><br><span class="line"># 构建训练数据</span><br><span class="line"># np.linspace()在-1和1之间等差生成300个数字</span><br><span class="line"># noise是正态分布的噪声，前两个参数是正态分布的参数，然后是size</span><br><span class="line">x_data = np.linspace(-1,1,300, dtype=np.float32)[:, np.newaxis]</span><br><span class="line">noise = np.random.normal(0, 0.05,  x_data.shape).astype(np.float32)</span><br><span class="line">y_data = np.square(x_data) - 0.5 + noise</span><br><span class="line"> </span><br><span class="line"># 利用占位符定义我们所需的神经网络的输入。</span><br><span class="line"># 第二个参数为shape：None代表行数不定，1是列数。</span><br><span class="line"># 这里的行数就是样本数，列数是每个样本的特征数。</span><br><span class="line">xs = tf.placeholder(tf.float32, [None, 1])</span><br><span class="line">ys = tf.placeholder(tf.float32, [None, 1])</span><br><span class="line"> </span><br><span class="line"># 输入层1个神经元（因为只有一个特征），隐藏层10个，输出层1个。</span><br><span class="line"># 调用函数定义隐藏层和输出层，输入size是上一层的神经元个数（全连接），输出size是本层个数。</span><br><span class="line">l1 = add_layer(xs, 1, 10, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(l1, 10, 1, activation_function=None)</span><br><span class="line"> </span><br><span class="line"># 计算预测值prediction和真实值的误差，对二者差的平方求和再取平均作为损失函数。</span><br><span class="line"># reduction_indices表示最后数据的压缩维度，好像一般不用这个参数（即降到0维，一个标量）。</span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),reduction_indices=[1]))</span><br><span class="line">train_step =  tf.train.GradientDescentOptimizer(0.1).minimize(loss)</span><br><span class="line"> </span><br><span class="line"># 初始化变量，激活，执行运算</span><br><span class="line">init = tf.global_variables_initializer() </span><br><span class="line">with tf.Session() as sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        # training</span><br><span class="line">        sess.run(train_step,feed_dict=&#123;xs:x_data,ys:y_data&#125;)</span><br><span class="line">        if i % 50 == 0:</span><br><span class="line">            print sess.run(loss,feed_dict&#123;xs:x_data,ys:y_data&#125;)</span><br></pre></td></tr></table></figure></p>

            </div>

            <!-- Post Comments -->
            
    <!-- 使用 DISQUS_CLICK -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>

<!-- add animation -->
<style>
	.disqus_click_btn {
            line-height: 30px;
            margin: 0;
            min-width: 50px;
            padding: 0 14px;
            display: inline-block;
            font-family: "Roboto", "Helvetica", "Arial", sans-serif;
            font-size: 14px;
            font-weight: 400;
            text-transform: uppercase;
            letter-spacing: 0;
            overflow: hidden;
            will-change: box-shadow;
            transition: box-shadow .2s cubic-bezier(.4, 0, 1, 1), background-color .2s cubic-bezier(.4, 0, .2, 1), color .2s cubic-bezier(.4, 0, .2, 1);
            outline: 0;
            cursor: pointer;
            text-decoration: none;
            text-align: center;
            vertical-align: middle;
            border: 0;
            background: rgba(158, 158, 158, .2);
            box-shadow: 0 2px 2px 0 rgba(0, 0, 0, .14), 0 3px 1px -2px rgba(0, 0, 0, .2), 0 1px 5px 0 rgba(0, 0, 0, .12);
            color: #fff;
            background-color: #7EC0EE;
            text-shadow: 0
        }
</style>
	
<div class="btn_click_load" id="disqus_bt"> 
    <button class="disqus_click_btn">点击查看评论</button>
</div>

<!--
<script type="text/javascript">
$('.btn_click_load').click(function() {
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'http-miccall-tech'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    document.getElementById('disqus_bt').style.display = "none";
});
</script>
-->
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'http://yoursite.com/2018/09/22/tensorflow入门/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://yoursite.com/2018/09/22/tensorflow入门/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>

<script type="text/javascript">
    $('.btn_click_load').click(function() {  //click to load comments
        (function() { // DON'T EDIT BELOW THIS LINE
            var d = document;
            var s = d.createElement('script');
            s.src = '//http-miccall-tech.disqus.com/embed.js';
            s.setAttribute('data-timestamp', + new Date());
            (d.head || d.body).appendChild(s);
        })();
        $('.btn_click_load').css('display','none');
    });
</script>
</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>


        </div>
        <!-- Copyright 版权 start -->
                <div id="copyright">
            <ul>
                <li>&copy;Powered By <a href="https://www.szu.edu.cn/" style="border-bottom: none;">深圳大学渣渣硕士李强--个人专属博客</a></li>
                <li>Design: <a href="https://www.szugod.cn " style="border-bottom: none;">李强（alex M.K）</a></li>
            </ul>
            
            	<span id="busuanzi_container_site_pv">2018总访问量<span id="busuanzi_value_site_pv"></span>次</span>
			
        </div>
    </div>
</body>



 	
</html>
